{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a (simple) Convolutional Neural Network\n",
    "\n",
    "In this notebook we implement a simple ConvNN architecture.\n",
    "The focus lies on understanding the key components of the network, such as Conv2d-layers, Max-Pooling and (most importantly) how all the dimensions play out.\n",
    "\n",
    "We test our architecture on the MNIST-dataset (as if there was any other option)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the digits data set\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 3, 2) # [1, 6, 5, 5]\n",
    "        self.conv2 = nn.Conv2d(3, 6, 1) # [1, 16, 2, 2]\n",
    "        \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(6 * 3 * 3, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # -> [1, 6, 2, 2]\n",
    "\n",
    "        x = F.relu(self.conv2(x), (2,2))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at model architecture and test if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv2): Conv2d(3, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=54, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0182, -0.2177, -0.4765,  0.2735,  0.0639,  0.2117,  0.0493, -0.2719,\n",
       "         -0.0214, -0.3175]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1 = digits.images[0]\n",
    "image1 = image1.reshape(1,1,8,8)\n",
    "image1t = torch.from_numpy(image1).float()\n",
    "model(image1t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Simple SGD optimizer with static learning rate, no weight decay, no momentum\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "\n",
    "# build a loss function\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training ... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training ... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.progress import track\n",
    "\n",
    "for epoch in track(range(10), 'Training ...'):\n",
    "    \n",
    "    print(f\"Finished {epoch=}\")\n",
    "    for idx in range(digits.images.shape[0]):\n",
    "        \n",
    "        # transform image to tensor\n",
    "        image = digits.images[idx]\n",
    "        image_t = torch.from_numpy(image.reshape(1,1,8,8)).float()\n",
    "\n",
    "        # get target vector & flip the right vector\n",
    "        target = torch.zeros((1,10))\n",
    "        target[0, digits.target[idx]] = 1\n",
    "        \n",
    "        # calculate prediction\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(image_t)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = mse(prediction, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch training\n",
    "\n",
    "Because training in batches is such an important concept in PyTorch (e.g. all layers and modules accept the batch-size as first dimension) I have included an example of how to train in batches.\n",
    "\n",
    "When executed, one can see just how much faster this goes through. Notice how we are going through 100 epochs faster this way than we were going trough 10 the cell before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Training ... <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Training ... \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.progress import track\n",
    "\n",
    "targets = torch.zeros(digits.images.shape[0], 10)\n",
    "for idx in range(targets.shape[0]):\n",
    "    targets[idx, digits.target[idx]] = 1\n",
    "\n",
    "for epoch in track(range(100), 'Training ...'):\n",
    "    \n",
    "    # batch training\n",
    "    images_t = torch.from_numpy(digits.images).float()\n",
    "    images_t = images_t.view(1797, 1, 8, 8)\n",
    "    \n",
    "    # predict for all images at once\n",
    "    optimizer.zero_grad()\n",
    "    predictions = model(images_t)\n",
    "    \n",
    "    losses = mse(predictions, targets)\n",
    "    losses.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Notes\n",
    "\n",
    "There are things missing here that will be included in other documents, such as:\n",
    "- DataLoaders\n",
    "- Cross Validation\n",
    "- Validation Plots\n",
    "- Better Optimizer\n",
    "- Hyperparameter Tuning\n",
    "- ...\n",
    "\n",
    "Thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-path",
   "language": "python",
   "name": "pytorch-path"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
