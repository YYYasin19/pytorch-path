{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Architecture\n",
    "\n",
    "In this notebook we are going to dive into the Attention mechanism in Sequence2Sequence models to understand how they work and can be implemented in PyTorch.\n",
    "\n",
    "This is needed so we can later, in another Notebook, understand the Transformer Model and apply it correctly.\n",
    "For reading up on the Attention mechanism, I propose [this blog article](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) which explains the concept in a visual yet detailed way.\n",
    "Additionally, the PyTorch Tutorials also give a good explanation on the subject: [Link](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import sys\n",
    "# sys.path.insert(0, '.') # searches this directory too -> ensures that imports work fine.\n",
    "\n",
    "# from modules.tatoeba import TatoebaDataset\n",
    "from modules.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.tatoeba import TatoebaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/deu-eng/deu.txt', sep=\"\\t\", names=['en', 'de', 'license'])\n",
    "ttds = TatoebaDataset(data, max_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "en, de = ttds[0]"
   ]
  },
  {
   "source": [
    "## The Encoder Architecture\n",
    "\n",
    "The encoder will take our \"word-ids\" (remember the Tokenizer) and encode them into a a vector: The hidden representation. Lateron our decoder network will use this hidden representation to generate the needed output."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('pytorch-path': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "c133cf9be758c35ebeb78e620c4ff535f87a940c93836c640d7b902017586f6b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}