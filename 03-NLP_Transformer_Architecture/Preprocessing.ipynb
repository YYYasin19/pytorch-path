{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "In this notebook we are going to perform the work needed for using the data with our models.\n",
    "This includes the following steps:\n",
    "\n",
    "1. Analyzing the data\n",
    "2. Preprocessing the data\n",
    "3. Writing a DataLoader to ensure it can be used with our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We are going to use a classic dataset: The [Tab-delimited Bilingual Sentence Pairs](http://www.manythings.org/anki/) from the [Tatoeba project](https://tatoeba.org/en).\n",
    "\n",
    "Since I am a native German speaker (and therefore can check the results the fastest in), we are going to use the Eng-Deu dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>de</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>We try.</td>\n",
       "      <td>Wir versuchen es.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>We won.</td>\n",
       "      <td>Wir haben gewonnen.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>It's his.</td>\n",
       "      <td>Es ist seins.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>It's hot.</td>\n",
       "      <td>Es ist heiß.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>They were busy.</td>\n",
       "      <td>Sie waren beschäftigt.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>They were dead.</td>\n",
       "      <td>Sie waren tot.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    en                      de  \\\n",
       "100            We try.       Wir versuchen es.   \n",
       "101            We won.     Wir haben gewonnen.   \n",
       "500          It's his.           Es ist seins.   \n",
       "501          It's hot.            Es ist heiß.   \n",
       "10000  They were busy.  Sie waren beschäftigt.   \n",
       "10001  They were dead.          Sie waren tot.   \n",
       "\n",
       "                                                 license  \n",
       "100    CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "101    CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "500    CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "501    CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "10000  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "10001  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/deu-eng/deu.txt', sep='\\t', names=['en', 'de', 'license'])\n",
    "data.iloc[np.r_[100:102, 500:502, 10000:10002]] # display some parts of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing\n",
    "\n",
    "Instead of implementing various methods for splitting words, removing non-ascii chars, etc. we are just letting nltk do all the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'How', 'are', 'you', 'doing', '?', '✅']\n",
      "[\"b'Hello\", '!', 'How', 'are', 'you', 'doing', '?', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "test =  \"Hello! How are you doing?✅\"\n",
    "print(word_tokenize(test))\n",
    "print(word_tokenize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(strip_accents='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentences = data.loc[:, ['en']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(strip_accents='ascii')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(en_sentences.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16334)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(['Hello! How are you doing?']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.vocabulary_.get('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6895.],\n",
       "        [ 7174.],\n",
       "        [  992.],\n",
       "        [16285.],\n",
       "        [ 4537.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"hello how are you doing\"\n",
    "torch.Tensor([cv.vocabulary_[s] for s in sentence.split(\" \")]).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-path",
   "language": "python",
   "name": "pytorch-path"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
